import streamlit as st
import pandas as pd
import openpyxl
from openpyxl import load_workbook
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import re
from datetime import datetime
import json

# Import OpenAI (optional)
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ƒê·ªçc API key t·ª´ config (n·∫øu c√≥)
try:
    from config import OPENAI_API_KEY as DEFAULT_API_KEY
except ImportError:
    DEFAULT_API_KEY = None

st.set_page_config(
    page_title="L·∫•y th√¥ng tin CCCD",
    page_icon="üÜî",
    layout="wide"
)

st.title("üÜî L·∫§Y TH√îNG TIN NH√ÇN VI√äN T·ª™ CCCD")
st.markdown("---")

# C·∫•u h√¨nh tesseract (n·∫øu c·∫ßn)
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

EXCEL_FILE = "Ket_qua_CCCD.xlsx"

def extract_text_with_ocr(image):
    """Tr√≠ch xu·∫•t text t·ª´ ·∫£nh s·ª≠ d·ª•ng OCR c∆° b·∫£n"""
    try:
        # S·ª≠ d·ª•ng OCR c∆° b·∫£n v·ªõi ng√¥n ng·ªØ ti·∫øng Vi·ªát v√† ti·∫øng Anh
        text = pytesseract.image_to_string(image, lang='vie+eng')
        return text
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc OCR: {str(e)}")
        return ""

def extract_cccd_with_openai(text_front, text_back, api_key):
    """S·ª≠ d·ª•ng OpenAI API ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin t·ª´ text OCR CCCD"""
    if not OPENAI_AVAILABLE:
        return None
    
    try:
        client = OpenAI(api_key=api_key)
        
        full_text = f"M·∫∂T TR∆Ø·ªöC:\n{text_front}\n\nM·∫∂T SAU:\n{text_back}"
        
        prompt = f"""B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin t·ª´ CCCD (CƒÉn c∆∞·ªõc c√¥ng d√¢n) Vi·ªát Nam. H√£y ph√¢n t√≠ch text OCR sau ƒë√¢y v√† tr√≠ch xu·∫•t th√¥ng tin theo ƒë·ªãnh d·∫°ng JSON.

Text OCR t·ª´ CCCD:
{full_text}

H√£y tr√≠ch xu·∫•t c√°c th√¥ng tin sau (PH·∫¢I GI·ªÆ NGUY√äN d·∫•u ti·∫øng Vi·ªát v√† ƒê·ªåC CH√çNH X√ÅC s·ªë):
1. S·ªë CCCD: S·ªë cƒÉn c∆∞·ªõc c√¥ng d√¢n (12 ch·ªØ s·ªë) - th∆∞·ªùng ·ªü ƒë·ªãnh d·∫°ng "S·ªë / No.: 080188012880" ho·∫∑c t∆∞∆°ng t·ª±
2. H·ªç v√† t√™n: H·ªç v√† t√™n ƒë·∫ßy ƒë·ªß (GI·ªÆ NGUY√äN d·∫•u ti·∫øng Vi·ªát)
3. Ng√†y sinh: Format DD/MM/YYYY - ƒê·ªåC CH√çNH X√ÅC t·ª´ng s·ªë, ƒë·∫∑c bi·ªát l√† nƒÉm (v√≠ d·ª•: 01/01/1988 kh√¥ng ph·∫£i 01/01/1980)
4. Gi·ªõi t√≠nh: Nam ho·∫∑c N·ªØ
5. Qu·ªëc t·ªãch: Th∆∞·ªùng l√† "Vi·ªát Nam" ho·∫∑c "Vietnam"
6. Qu√™ qu√°n: ƒê·ªãa ch·ªâ qu√™ qu√°n (GI·ªÆ NGUY√äN d·∫•u ti·∫øng Vi·ªát) - L∆ØU √ù: Gi√° tr·ªã c√≥ th·ªÉ n·∫±m ·ªü D√íNG D∆Ø·ªöI sau t·ª´ kh√≥a "Qu√™ qu√°n / Place of origin:" v√† c√≥ th·ªÉ tr·∫£i d√†i nhi·ªÅu d√≤ng. GH√âP T·∫§T C·∫¢ c√°c d√≤ng l·∫°i th√†nh m·ªôt ƒë·ªãa ch·ªâ ƒë·∫ßy ƒë·ªß.
7. N∆°i th∆∞·ªùng tr√∫: ƒê·ªãa ch·ªâ th∆∞·ªùng tr√∫ (GI·ªÆ NGUY√äN d·∫•u ti·∫øng Vi·ªát) - L∆ØU √ù: Gi√° tr·ªã c√≥ th·ªÉ B·∫ÆT ƒê·∫¶U C√ôNG D√íNG v·ªõi t·ª´ kh√≥a (sau d·∫•u :) v√† TI·∫æP T·ª§C ·ªü c√°c d√≤ng d∆∞·ªõi. GH√âP T·∫§T C·∫¢ c√°c d√≤ng l·∫°i th√†nh m·ªôt ƒë·ªãa ch·ªâ ƒë·∫ßy ƒë·ªß (v√≠ d·ª•: "637/10/33/30P H√† Huy Gi√°p, KP2, Th·∫°nh Xu√¢n, Q12, TP. HCM")
8. Ng√†y c·∫•p: Format DD/MM/YYYY - ƒê·ªåC CH√çNH X√ÅC t·ª´ng s·ªë
9. N∆°i c·∫•p: T√™n c∆° quan c·∫•p (GI·ªÆ NGUY√äN d·∫•u ti·∫øng Vi·ªát)

L∆ØU √ù QUAN TR·ªåNG:
- C√ÅC TH√îNG TIN TR√äN CCCD C√ì TH·ªÇ KH√îNG TH·∫≤NG H√ÄNG: T√¨m t·ª´ kh√≥a (v√≠ d·ª•: "Ng√†y sinh / Date of birth:") r·ªìi t√¨m gi√° tr·ªã trong PH·∫†M VI R·ªòNG quanh ƒë√≥, kh√¥ng ch·ªâ tr√™n c√πng m·ªôt d√≤ng.
- V√≠ d·ª•: N·∫øu th·∫•y "Ng√†y sinh / Date of birth:" nh∆∞ng ng√†y th√°ng nƒÉm ·ªü d√≤ng kh√°c ho·∫∑c b·ªã l·ªách, v·∫´n ph·∫£i tr√≠ch xu·∫•t ƒë√∫ng.
- OCR c√≥ th·ªÉ ƒë·ªçc sai d·∫•u ti·∫øng Vi·ªát ho·∫∑c s·ªë. B·∫°n PH·∫¢I t·ª± ƒë·ªông s·ª≠a l·∫°i d·∫•u v√† s·ªë cho ƒë√∫ng d·ª±a tr√™n ng·ªØ c·∫£nh v√† ki·∫øn th·ª©c ti·∫øng Vi·ªát/ƒë·ªãnh d·∫°ng CCCD.
- V√≠ d·ª• s·ª≠a d·∫•u: "TON" -> "T√îN", "THANH" -> "TH√ÄNH", "DAT" -> "ƒê·∫†T", "CONG" -> "C√îNG", "DONG" -> "ƒê√îNG"
- NG√ÄY SINH: ƒê·ªçc CH√çNH X√ÅC t·ª´ng ch·ªØ s·ªë. N·∫øu th·∫•y "01/01/1988" th√¨ ph·∫£i l√† "01/01/1988", KH√îNG ph·∫£i "01/01/1980" hay "01/01/1990". Ki·ªÉm tra k·ªπ s·ªë cu·ªëi c√πng c·ªßa nƒÉm (v√≠ d·ª•: 1988 c√≥ s·ªë 8 cu·ªëi, kh√¥ng ph·∫£i 0).
- ƒê·∫£m b·∫£o t·∫•t c·∫£ th√¥ng tin ƒë·ªãa ch·ªâ, t√™n ƒë·ªÅu c√≥ d·∫•u ti·∫øng Vi·ªát ch√≠nh x√°c
- S·ªë CCCD ph·∫£i l√† 12 ch·ªØ s·ªë v√† ch√≠nh x√°c, t√¨m sau "S·ªë / No.:"

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
    "S·ªë CCCD": "001234567890",
    "H·ªç v√† t√™n": "NGUY·ªÑN VƒÇN A",
    "Ng√†y sinh": "01/01/1990",
    "Gi·ªõi t√≠nh": "Nam",
    "Qu·ªëc t·ªãch": "Vi·ªát Nam",
    "Qu√™ qu√°n": "X√£ ABC, Huy·ªán XYZ, T·ªânh DEF",
    "N∆°i th∆∞·ªùng tr√∫": "S·ªë 123 ƒê∆∞·ªùng ABC, Ph∆∞·ªùng XYZ, Th√†nh ph·ªë DEF",
    "Ng√†y c·∫•p": "01/01/2020",
    "N∆°i c·∫•p": "C·ª§C C·∫¢NH S√ÅT ƒêKQL C∆Ø TR√ö V√Ä DLQG V·ªÄ D√ÇN C∆Ø"
}}

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng c√≥ text th√™m."""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th√¥ng tin t·ª´ CCCD Vi·ªát Nam. Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON ch√≠nh x√°c v·ªõi d·∫•u ti·∫øng Vi·ªát ƒë√∫ng."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=2000
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Lo·∫°i b·ªè markdown code block n·∫øu c√≥
        if result_text.startswith("```json"):
            result_text = result_text[7:]
        if result_text.startswith("```"):
            result_text = result_text[3:]
        if result_text.endswith("```"):
            result_text = result_text[:-3]
        
        result_text = result_text.strip()
        
        # Parse JSON
        result = json.loads(result_text)
        return result
        
    except json.JSONDecodeError as e:
        st.warning(f"Kh√¥ng th·ªÉ parse JSON t·ª´ OpenAI: {str(e)}")
        return None
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi OpenAI API: {str(e)}")
        return None

def process_cccd_extraction(image_front, image_back, use_openai, api_key):
    """X·ª≠ l√Ω tr√≠ch xu·∫•t th√¥ng tin CCCD, c√≥ th·ªÉ d√πng OpenAI n·∫øu ƒë∆∞·ª£c b·∫≠t"""
    try:
        # ƒê·ªçc text t·ª´ OCR c∆° b·∫£n
        text_front = extract_text_with_ocr(image_front)
        text_back = extract_text_with_ocr(image_back)
        
        # S·ª≠ d·ª•ng OpenAI n·∫øu ƒë∆∞·ª£c b·∫≠t v√† c√≥ API key
        if use_openai and api_key and OPENAI_AVAILABLE:
            with st.spinner("ü§ñ ƒêang s·ª≠ d·ª•ng OpenAI ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin..."):
                openai_data = extract_cccd_with_openai(text_front, text_back, api_key)
                if openai_data:
                    st.success("‚úÖ ƒê√£ s·ª≠ d·ª•ng OpenAI ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin")
                    return openai_data, text_front + "\n" + text_back
                else:
                    # Fallback v·ªÅ ph∆∞∆°ng ph√°p c≈©
                    st.info("‚ÑπÔ∏è S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p OCR th√¥ng th∆∞·ªùng")
                    info, full_text = extract_cccd_info(image_front, image_back)
                    return info, full_text
        else:
            info, full_text = extract_cccd_info(image_front, image_back)
            return info, full_text
            
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω OCR: {str(e)}")
        return None, ""

def extract_cccd_info(image_front, image_back):
    """Tr√≠ch xu·∫•t th√¥ng tin t·ª´ ·∫£nh CCCD m·∫∑t tr∆∞·ªõc v√† sau"""
    info = {
        'S·ªë CCCD': '',
        'H·ªç v√† t√™n': '',
        'Ng√†y sinh': '',
        'Gi·ªõi t√≠nh': '',
        'Qu·ªëc t·ªãch': '',
        'Qu√™ qu√°n': '',
        'N∆°i th∆∞·ªùng tr√∫': '',
        'Ng√†y c·∫•p': '',
        'N∆°i c·∫•p': ''
    }
    
    try:
        # ƒê·ªçc text t·ª´ m·∫∑t tr∆∞·ªõc
        text_front = extract_text_with_ocr(image_front)
        
        # ƒê·ªçc text t·ª´ m·∫∑t sau
        text_back = extract_text_with_ocr(image_back)
        
        full_text = text_front + "\n" + text_back
        
        # Tr√≠ch xu·∫•t s·ªë CCCD - ƒë·ªãnh d·∫°ng "S·ªë / No.: 080188012880"
        # T√¨m t·ª´ kh√≥a "S·ªë / No.:" ho·∫∑c t∆∞∆°ng t·ª±, sau ƒë√≥ l·∫•y s·ªë 12 ch·ªØ s·ªë ngay sau ƒë√≥
        so_no_pattern = r'(?:S·ªë|SO)\s*[/\\]\s*No\.?\s*[:]'
        so_no_match = re.search(so_no_pattern, text_front, re.IGNORECASE)
        
        if so_no_match:
            # L·∫•y text sau "S·ªë / No.:"
            text_after_label = text_front[so_no_match.end():]
            # T√¨m s·ªë 12 ch·ªØ s·ªë ƒë·∫ßu ti√™n ngay sau label (trong v√≤ng 50 k√Ω t·ª±)
            number_match = re.search(r'\s*(\d{12})(?:\s|$|\n|[^\d])', text_after_label[:50])
            if number_match:
                cccd_number = number_match.group(1).replace(' ', '').replace('-', '').replace('.', '')
                if len(cccd_number) == 12 and cccd_number.isdigit():
                    info['S·ªë CCCD'] = cccd_number
        else:
            # Fallback: th·ª≠ c√°c pattern kh√°c n·∫øu kh√¥ng t√¨m th·∫•y "S·ªë / No.:"
            cccd_patterns = [
                r'(?:S·ªë|SO)\s*[/\\]?\s*No\.?\s*[:]?\s*(\d{12})(?:\s|$|\n)',  # "S·ªë / No: 080188012880"
                r'(?:S·ªë|SO)[\s:]*(\d{12})(?:\s|$|\n)',  # "S·ªë: 080188012880"
                r'No\.\s*[:]?\s*(\d{12})(?:\s|$|\n)',  # "No.: 080188012880"
            ]
            for pattern in cccd_patterns:
                match = re.search(pattern, text_front, re.IGNORECASE | re.MULTILINE)
                if match:
                    cccd_number = match.group(1).replace(' ', '').replace('-', '').replace('.', '')
                    if len(cccd_number) == 12 and cccd_number.isdigit():
                        info['S·ªë CCCD'] = cccd_number
                        break
        
        # Tr√≠ch xu·∫•t h·ªç v√† t√™n - t√¨m trong ph·∫°m vi r·ªông
        name_keyword_pattern = r'(?:H·ªç v√† t√™n|H·ªå V√Ä T√äN|H·ªç, ch·ªØ ƒë·ªám v√† t√™n|Full name|Name)\s*[/\\]?\s*(?:Full name|Name)?\s*[:]'
        name_keyword_match = re.search(name_keyword_pattern, text_front, re.IGNORECASE)
        
        if name_keyword_match:
            # L·∫•y text trong ph·∫°m vi 150 k√Ω t·ª± sau t·ª´ kh√≥a
            text_around_name = text_front[name_keyword_match.end():name_keyword_match.end() + 150]
            # T√¨m t√™n (d√≤ng ch·ªØ in hoa, c√≥ th·ªÉ c√≥ nhi·ªÅu t·ª´)
            name_pattern = r'([A-Z√Ä-·ª∏][A-Z√Ä-·ª∏\s]{5,50}?)(?=\n|Ng√†y|Date|Gi·ªõi|Sex|Gender|$)'
            match = re.search(name_pattern, text_around_name)
            if match:
                info['H·ªç v√† t√™n'] = match.group(1).strip()
        else:
            # Fallback: pattern th√¥ng th∆∞·ªùng
            name_patterns = [
                r'(?:H·ªç v√† t√™n|H·ªå V√Ä T√äN|H·ªç, ch·ªØ ƒë·ªám v√† t√™n)[\s:]*([A-Z√Ä-·ª∏][A-Z√Ä-·ª∏\s]+?)(?:\n|Ng√†y)',
                r'(?:Full name|Name)[\s:]*([A-Z√Ä-·ª∏][A-Z√Ä-·ª∏\s]+?)(?:\n|Date)'
            ]
            for pattern in name_patterns:
                match = re.search(pattern, text_front, re.IGNORECASE)
                if match:
                    info['H·ªç v√† t√™n'] = match.group(1).strip()
                    break
        
        # Tr√≠ch xu·∫•t ng√†y sinh - t√¨m trong ph·∫°m vi r·ªông quanh t·ª´ kh√≥a
        dob_keyword_pattern = r'(?:Ng√†y sinh|Date of birth|DOB)\s*[/\\]?\s*Date of birth\s*[:]'
        dob_keyword_match = re.search(dob_keyword_pattern, text_front, re.IGNORECASE)
        
        if dob_keyword_match:
            # L·∫•y text trong ph·∫°m vi 100 k√Ω t·ª± sau t·ª´ kh√≥a (ƒë·ªÉ b·∫Øt ng√†y kh√¥ng th·∫≥ng h√†ng)
            text_around_dob = text_front[dob_keyword_match.start():dob_keyword_match.end() + 100]
            # T√¨m ng√†y trong ph·∫°m vi n√†y
            date_pattern = r'(\d{2})[\/\-](\d{2})[\/\-](\d{4})'
            match = re.search(date_pattern, text_around_dob)
            if match:
                day, month, year = match.groups()
                info['Ng√†y sinh'] = f"{day}/{month}/{year}"
        else:
            # Fallback: t√¨m pattern th√¥ng th∆∞·ªùng
            dob_patterns = [
                r'(?:Ng√†y sinh|Date of birth|DOB)[\s:/\\]*Date of birth\s*[:]\s*(\d{2})[\/\-](\d{2})[\/\-](\d{4})',
                r'(?:Ng√†y sinh|Date of birth|DOB)[\s:]*(\d{2})[\/\-](\d{2})[\/\-](\d{4})',
                r'(\d{2})[\/\-](\d{2})[\/\-](\d{4})'
            ]
            for pattern in dob_patterns:
                match = re.search(pattern, text_front, re.IGNORECASE | re.MULTILINE)
                if match:
                    day, month, year = match.groups()
                    info['Ng√†y sinh'] = f"{day}/{month}/{year}"
                    break
        
        # Tr√≠ch xu·∫•t gi·ªõi t√≠nh - t√¨m trong ph·∫°m vi r·ªông
        gender_keyword_pattern = r'(?:Gi·ªõi t√≠nh|Sex|Gender)\s*[/\\]?\s*(?:Sex|Gender)?\s*[:]'
        gender_keyword_match = re.search(gender_keyword_pattern, text_front, re.IGNORECASE)
        
        if gender_keyword_match:
            # L·∫•y text trong ph·∫°m vi 50 k√Ω t·ª± sau t·ª´ kh√≥a
            text_around_gender = text_front[gender_keyword_match.end():gender_keyword_match.end() + 50]
            gender_pattern = r'\s*((?:Nam|N·ªØ|Male|Female|NAM|N·ªÆ))'
            match = re.search(gender_pattern, text_around_gender, re.IGNORECASE)
            if match:
                info['Gi·ªõi t√≠nh'] = match.group(1).strip()
        else:
            # Fallback
            gender_patterns = [
                r'(?:Gi·ªõi t√≠nh|Sex|Gender)[\s:]*((?:Nam|N·ªØ|Male|Female|NAM|N·ªÆ))',
                r'(Nam|N·ªØ|Male|Female)'
            ]
            for pattern in gender_patterns:
                match = re.search(pattern, text_front, re.IGNORECASE)
                if match:
                    info['Gi·ªõi t√≠nh'] = match.group(1).strip()
                    break
        
        # Tr√≠ch xu·∫•t qu·ªëc t·ªãch - t√¨m trong ph·∫°m vi r·ªông
        nationality_keyword_pattern = r'(?:Qu·ªëc t·ªãch|Nationality)\s*[/\\]?\s*(?:Nationality)?\s*[:]'
        nationality_keyword_match = re.search(nationality_keyword_pattern, text_front, re.IGNORECASE)
        
        if nationality_keyword_match:
            # L·∫•y text trong ph·∫°m vi 100 k√Ω t·ª± sau t·ª´ kh√≥a
            text_around_nationality = text_front[nationality_keyword_match.end():nationality_keyword_match.end() + 100]
            nationality_pattern = r'\s*([A-Z√Ä-·ª∏\s]{2,50}?)(?=\n|Qu√™|Place|Origin|$)'
            match = re.search(nationality_pattern, text_around_nationality)
            if match:
                info['Qu·ªëc t·ªãch'] = match.group(1).strip()
        else:
            # Fallback
            nationality_patterns = [
                r'(?:Qu·ªëc t·ªãch|Nationality)[\s:]*([A-Z√Ä-·ª∏\s]+?)(?:\n|Qu√™)',
                r'(Vietnam|Vi·ªát Nam|VN)'
            ]
            for pattern in nationality_patterns:
                match = re.search(pattern, text_front, re.IGNORECASE)
                if match:
                    info['Qu·ªëc t·ªãch'] = match.group(1).strip() if match.lastindex and match.group(1) else "Vi·ªát Nam"
                    break
        
        # Tr√≠ch xu·∫•t qu√™ qu√°n - th∆∞·ªùng ·ªü d√≤ng d∆∞·ªõi, c√≥ th·ªÉ nhi·ªÅu d√≤ng
        # Pattern linh ho·∫°t h∆°n ƒë·ªÉ t√¨m t·ª´ kh√≥a
        que_quan_keyword_patterns = [
            r'Qu√™ qu√°n\s*[/\\]?\s*Place of origin\s*[:]',
            r'Qu√™ qu√°n\s*[:]',
            r'Place of origin\s*[:]'
        ]
        que_quan_keyword_match = None
        for pattern in que_quan_keyword_patterns:
            que_quan_keyword_match = re.search(pattern, text_front, re.IGNORECASE)
            if que_quan_keyword_match:
                break
        
        if que_quan_keyword_match:
            # L·∫•y text trong ph·∫°m vi 400 k√Ω t·ª± sau t·ª´ kh√≥a
            text_after_keyword = text_front[que_quan_keyword_match.end():que_quan_keyword_match.end() + 400]
            
            # T√°ch th√†nh c√°c d√≤ng (x·ª≠ l√Ω c·∫£ \n v√† \r\n)
            lines_after = re.split(r'\r?\n', text_after_keyword)
            
            # Thu th·∫≠p c√°c d√≤ng ƒë·ªãa ch·ªâ (c√≥ th·ªÉ nhi·ªÅu d√≤ng)
            address_lines = []
            
            # ƒê·ªçc c√°c d√≤ng sau t·ª´ kh√≥a (t·ªëi ƒëa 4 d√≤ng) cho ƒë·∫øn khi g·∫∑p t·ª´ kh√≥a m·ªõi
            for i, line in enumerate(lines_after[:4]):  # Xem 4 d√≤ng ƒë·∫ßu
                line = line.strip()
                # Lo·∫°i b·ªè t·ª´ kh√≥a n·∫øu c√≤n s√≥t
                line = re.sub(r'^(?:Qu√™ qu√°n|Place of origin|Origin)[\s:/\\]*', '', line, flags=re.IGNORECASE).strip()
                
                # D·ª´ng n·∫øu g·∫∑p t·ª´ kh√≥a m·ªõi (N∆°i th∆∞·ªùng tr√∫, Permanent address, Qu·ªëc t·ªãch)
                if re.match(r'^(?:N∆°i th∆∞·ªùng tr√∫|Permanent address|Address|Qu·ªëc t·ªãch|Nationality)', line, re.IGNORECASE):
                    break
                # Th√™m d√≤ng n·∫øu c√≥ v·∫ª l√† ƒë·ªãa ch·ªâ (b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ hoa ti·∫øng Vi·ªát, c√≥ d·∫•u ph·∫©y, ho·∫∑c c√≥ ch·ªØ c√°i)
                if line and (re.match(r'^[A-Z√Ä-·ª∏]', line) or ',' in line):
                    address_lines.append(line)
                # N·∫øu d√≤ng tr·ªëng v√† ƒë√£ c√≥ √≠t nh·∫•t 1 d√≤ng ƒë·ªãa ch·ªâ, c√≥ th·ªÉ ƒë√£ k·∫øt th√∫c
                elif not line and address_lines:
                    break
            
            # Gh√©p c√°c d√≤ng l·∫°i th√†nh ƒë·ªãa ch·ªâ ƒë·∫ßy ƒë·ªß
            if address_lines:
                info['Qu√™ qu√°n'] = ' '.join(address_lines).strip()
        
        # Fallback: pattern th√¥ng th∆∞·ªùng n·∫øu ch∆∞a t√¨m ƒë∆∞·ª£c
        if not info.get('Qu√™ qu√°n'):
            que_quan_patterns = [
                r'Qu√™ qu√°n\s*[/\\]?\s*Place of origin\s*[:]\s*([A-Z√Ä-·ª∏][A-Z√Ä-·ª∏0-9/\s,\.\-]{5,150}?)(?=\n|N∆°i|Permanent|Address|Qu·ªëc|Nationality|$)',
                r'Qu√™ qu√°n\s*[:]\s*([A-Z√Ä-·ª∏][A-Z√Ä-·ª∏0-9/\s,\.\-]{5,150}?)(?=\n|N∆°i|$)',
                r'(?:Qu√™ qu√°n|Place of origin|Origin)[\s:]*([A-Z√Ä-·ª∏0-9/\s,\.\-]{5,150}?)(?=\n|N∆°i|Permanent|Address|Qu·ªëc|Nationality|$)'
            ]
            for pattern in que_quan_patterns:
                match = re.search(pattern, text_front, re.IGNORECASE | re.MULTILINE | re.DOTALL)
                if match:
                    value = match.group(1).strip()
                    if value:
                        info['Qu√™ qu√°n'] = value
                        break
        
        # Tr√≠ch xu·∫•t n∆°i th∆∞·ªùng tr√∫ - c√≥ th·ªÉ b·∫Øt ƒë·∫ßu c√πng d√≤ng v√† ti·∫øp t·ª•c ·ªü d√≤ng d∆∞·ªõi
        search_text = text_back or text_front
        # Pattern linh ho·∫°t h∆°n ƒë·ªÉ t√¨m t·ª´ kh√≥a
        thuong_tru_keyword_patterns = [
            r'N∆°i th∆∞·ªùng tr√∫\s*[/\\]?\s*Permanent address\s*[:]',
            r'N∆°i th∆∞·ªùng tr√∫\s*[/\\]?\s*Place of residence\s*[:]',
            r'N∆°i th∆∞·ªùng tr√∫\s*[:]',
            r'Permanent address\s*[:]'
        ]
        thuong_tru_keyword_match = None
        for pattern in thuong_tru_keyword_patterns:
            thuong_tru_keyword_match = re.search(pattern, search_text, re.IGNORECASE)
            if thuong_tru_keyword_match:
                break
        
        if thuong_tru_keyword_match:
            # L·∫•y text trong ph·∫°m vi 500 k√Ω t·ª± sau t·ª´ kh√≥a (ƒë·ªÉ b·∫Øt nhi·ªÅu d√≤ng)
            text_after_keyword = search_text[thuong_tru_keyword_match.end():thuong_tru_keyword_match.end() + 500]
            
            # T√°ch th√†nh c√°c d√≤ng (x·ª≠ l√Ω c·∫£ \n v√† \r\n)
            lines_after = re.split(r'\r?\n', text_after_keyword)
            
            # T√¨m ph·∫ßn c√≤n l·∫°i tr√™n c√πng d√≤ng (sau d·∫•u :)
            first_line_after_colon = lines_after[0] if lines_after else ""
            # Lo·∫°i b·ªè t·ª´ kh√≥a n·∫øu c√≤n s√≥t
            first_line_after_colon = re.sub(r'^(?:N∆°i th∆∞·ªùng tr√∫|Permanent address|Address|Place of residence)[\s:/\\]*', '', first_line_after_colon, flags=re.IGNORECASE).strip()
            
            # Thu th·∫≠p c√°c d√≤ng ƒë·ªãa ch·ªâ (c√≥ th·ªÉ nhi·ªÅu d√≤ng)
            address_lines = []
            
            # Th√™m ph·∫ßn c√≤n l·∫°i tr√™n d√≤ng ƒë·∫ßu n·∫øu c√≥ (b·∫Øt ƒë·∫ßu b·∫±ng s·ªë, ch·ªØ hoa, ho·∫∑c c√≥ d·∫•u ph·∫©y)
            if first_line_after_colon and (re.match(r'^[0-9A-Z√Ä-·ª∏/]', first_line_after_colon) or ',' in first_line_after_colon or '.' in first_line_after_colon):
                address_lines.append(first_line_after_colon)
            
            # ƒê·ªçc c√°c d√≤ng ti·∫øp theo (t·ªëi ƒëa 4 d√≤ng) cho ƒë·∫øn khi g·∫∑p t·ª´ kh√≥a m·ªõi
            for i, line in enumerate(lines_after[1:5], start=1):  # Xem 4 d√≤ng ti·∫øp theo
                line = line.strip()
                # D·ª´ng n·∫øu g·∫∑p t·ª´ kh√≥a m·ªõi (Ng√†y c·∫•p, Date of issue, ho·∫∑c t·ª´ kh√≥a kh√°c)
                if re.match(r'^(?:Ng√†y c·∫•p|Date of issue|Place of issue|Issued)', line, re.IGNORECASE):
                    break
                # Th√™m d√≤ng n·∫øu c√≥ v·∫ª l√† ƒë·ªãa ch·ªâ (b·∫Øt ƒë·∫ßu b·∫±ng s·ªë, ch·ªØ hoa, ho·∫∑c c√≥ d·∫•u ph·∫©y, d·∫•u ch·∫•m)
                if line and (re.match(r'^[0-9A-Z√Ä-·ª∏]', line) or ',' in line or '.' in line):
                    address_lines.append(line)
                # N·∫øu d√≤ng tr·ªëng v√† ƒë√£ c√≥ √≠t nh·∫•t 1 d√≤ng ƒë·ªãa ch·ªâ, c√≥ th·ªÉ ƒë√£ k·∫øt th√∫c
                elif not line and address_lines:
                    break
            
            # Gh√©p c√°c d√≤ng l·∫°i th√†nh ƒë·ªãa ch·ªâ ƒë·∫ßy ƒë·ªß
            if address_lines:
                info['N∆°i th∆∞·ªùng tr√∫'] = ' '.join(address_lines).strip()
        
        # Fallback: pattern th√¥ng th∆∞·ªùng n·∫øu ch∆∞a t√¨m ƒë∆∞·ª£c
        if not info.get('N∆°i th∆∞·ªùng tr√∫'):
            thuong_tru_patterns = [
                r'N∆°i th∆∞·ªùng tr√∫\s*[/\\]?\s*Permanent address\s*[:]\s*([0-9A-Z√Ä-·ª∏/][A-Z√Ä-·ª∏0-9/\s,\.\-]{10,200}?)(?=\n|Ng√†y|Date|$)',
                r'N∆°i th∆∞·ªùng tr√∫\s*[:]\s*([0-9A-Z√Ä-·ª∏/][A-Z√Ä-·ª∏0-9/\s,\.\-]{10,200}?)(?=\n|Ng√†y|$)',
                r'(?:N∆°i th∆∞·ªùng tr√∫|Permanent address|Place of residence)[\s:]*([0-9A-Z√Ä-·ª∏/][A-Z√Ä-·ª∏0-9/\s,\.\-]{10,200}?)(?=\n|Ng√†y|Date|$)'
            ]
            for pattern in thuong_tru_patterns:
                match = re.search(pattern, search_text, re.IGNORECASE | re.MULTILINE | re.DOTALL)
                if match:
                    value = match.group(1).strip()
                    if value:
                        info['N∆°i th∆∞·ªùng tr√∫'] = value
                        break
        
        # Tr√≠ch xu·∫•t ng√†y c·∫•p - t√¨m trong ph·∫°m vi r·ªông
        search_text_date = text_back or text_front
        # Pattern linh ho·∫°t h∆°n ƒë·ªÉ t√¨m t·ª´ kh√≥a
        ngay_cap_keyword_patterns = [
            r'Ng√†y c·∫•p\s*[/\\]?\s*Date of issue\s*[:]',
            r'Ng√†y c·∫•p\s*[:]',
            r'Date of issue\s*[:]',
            r'Issued date\s*[:]'
        ]
        ngay_cap_keyword_match = None
        for pattern in ngay_cap_keyword_patterns:
            ngay_cap_keyword_match = re.search(pattern, search_text_date, re.IGNORECASE)
            if ngay_cap_keyword_match:
                break
        
        if ngay_cap_keyword_match:
            # L·∫•y text trong ph·∫°m vi 100 k√Ω t·ª± sau t·ª´ kh√≥a
            text_around_ngay_cap = search_text_date[ngay_cap_keyword_match.end():ngay_cap_keyword_match.end() + 100]
            # T√¨m ng√†y trong ph·∫°m vi n√†y
            date_pattern = r'(\d{2})[\/\-](\d{2})[\/\-](\d{4})'
            match = re.search(date_pattern, text_around_ngay_cap)
            if match:
                day, month, year = match.groups()
                info['Ng√†y c·∫•p'] = f"{day}/{month}/{year}"
        
        # Fallback: pattern th√¥ng th∆∞·ªùng n·∫øu ch∆∞a t√¨m ƒë∆∞·ª£c
        if not info.get('Ng√†y c·∫•p'):
            ngay_cap_patterns = [
                r'(?:Ng√†y c·∫•p|Date of issue|Issued date)[\s:]*(\d{2})[\/\-](\d{2})[\/\-](\d{4})',
                r'(\d{2})[\/\-](\d{2})[\/\-](\d{4})'  # T√¨m b·∫•t k·ª≥ ng√†y n√†o trong text_back
            ]
            for pattern in ngay_cap_patterns:
                # ∆Øu ti√™n t√¨m trong text_back tr∆∞·ªõc
                match = re.search(pattern, text_back or text_front, re.IGNORECASE)
                if match:
                    day, month, year = match.groups()
                    info['Ng√†y c·∫•p'] = f"{day}/{month}/{year}"
                    break
        
        # Tr√≠ch xu·∫•t n∆°i c·∫•p
        noi_cap_patterns = [
            r'(?:N∆°i c·∫•p|Place of issue|Issued by)[\s:]*([A-Z√Ä-·ª∏0-9/\s,]+?)(?:\n|$)',
            r'(?:C∆° quan c·∫•p|Authority)[\s:]*([A-Z√Ä-·ª∏0-9/\s,]+?)(?:\n|$)'
        ]
        for pattern in noi_cap_patterns:
            match = re.search(pattern, text_back or text_front, re.IGNORECASE | re.MULTILINE)
            if match:
                info['N∆°i c·∫•p'] = match.group(1).strip()
                break
        
        return info, full_text
        
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc OCR: {str(e)}")
        return info, ""

def load_excel_data():
    """ƒê·ªçc d·ªØ li·ªáu t·ª´ file Excel"""
    try:
        wb = load_workbook(EXCEL_FILE)
        # L·∫•y sheet ƒë·∫ßu ti√™n (ho·∫∑c c√≥ th·ªÉ ch·ªâ ƒë·ªãnh t√™n sheet)
        ws = wb.active
        
        # L·∫•y d·ªØ li·ªáu
        data = []
        headers = []
        
        # ƒê·ªçc header t·ª´ h√†ng ƒë·∫ßu ti√™n
        if ws.max_row > 0:
            for idx, cell in enumerate(ws[1]):
                header_value = cell.value if cell.value else ''
                # X·ª≠ l√Ω c·ªôt tr√πng t√™n: th√™m index cho c·ªôt tr·ªëng
                if header_value == '':
                    header_value = f'Unnamed_{idx}'
                headers.append(header_value)
        
        # ƒê·ªçc d·ªØ li·ªáu t·ª´ h√†ng 2 tr·ªü ƒëi
        for row in ws.iter_rows(min_row=2, values_only=True):
            if any(row):
                data.append(row)
        
        if headers:
            # X·ª≠ l√Ω c·ªôt tr√πng t√™n tr∆∞·ªõc khi t·∫°o DataFrame
            unique_headers = []
            header_counts = {}
            for header in headers:
                if header and not header.startswith('Unnamed_'):
                    # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa header n√†y
                    count = header_counts.get(header, 0)
                    if count > 0:
                        unique_header = f"{header}_{count}"
                    else:
                        unique_header = header
                    header_counts[header] = count + 1
                    unique_headers.append(unique_header)
                else:
                    # B·ªè qua c·ªôt Unnamed
                    unique_headers.append(None)
            
            # T·∫°o DataFrame ch·ªâ v·ªõi c√°c c·ªôt h·ª£p l·ªá
            valid_indices = [i for i, h in enumerate(unique_headers) if h is not None]
            valid_headers = [unique_headers[i] for i in valid_indices]
            
            if data:
                valid_data = [[row[i] for i in valid_indices] for row in data]
                df = pd.DataFrame(valid_data, columns=valid_headers)
            else:
                df = pd.DataFrame(columns=valid_headers)
            
            return df
        else:
            return pd.DataFrame()
    except FileNotFoundError:
        st.warning(f"File {EXCEL_FILE} ch∆∞a t·ªìn t·∫°i. S·∫Ω ƒë∆∞·ª£c t·∫°o khi l∆∞u d·ªØ li·ªáu ƒë·∫ßu ti√™n.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file Excel: {str(e)}")
        return pd.DataFrame()

def create_labor_contract(cccd_data, template_file="HDLD_Mau.txt"):
    """T·∫°o h·ª£p ƒë·ªìng lao ƒë·ªông t·ª´ template v√† d·ªØ li·ªáu CCCD"""
    try:
        # ƒê·ªçc template
        with open(template_file, 'r', encoding='utf-8') as f:
            template = f.read()
        
        # L·∫•y ng√†y hi·ªán t·∫°i
        today = datetime.now()
        current_date = today.strftime("%d/%m/%Y")
        current_day = today.strftime("%d")
        current_month = today.strftime("%m")
        current_year = today.strftime("%Y")
        
        # Thay th·∫ø c√°c placeholder
        contract = template
        
        # Th√¥ng tin ng∆∞·ªùi lao ƒë·ªông
        ho_ten = cccd_data.get('H·ªç v√† t√™n', '')
        ngay_sinh = cccd_data.get('Ng√†y sinh', '')
        gioi_tinh = cccd_data.get('Gi·ªõi t√≠nh', '')
        quoc_tich = cccd_data.get('Qu·ªëc t·ªãch', '')
        so_cccd = cccd_data.get('S·ªë CCCD', '')
        ngay_cap = cccd_data.get('Ng√†y c·∫•p', '')
        noi_cap = cccd_data.get('N∆°i c·∫•p', '')
        que_quan = cccd_data.get('Qu√™ qu√°n', '')
        thuong_tru = cccd_data.get('N∆°i th∆∞·ªùng tr√∫', '')
        
        # X√°c ƒë·ªãnh "√îng" ho·∫∑c "B√†" d·ª±a v√†o gi·ªõi t√≠nh
        xung_ho = "√îng/b√†"
        if gioi_tinh and "Nam" in gioi_tinh:
            xung_ho = "√îng"
        elif gioi_tinh and "N·ªØ" in gioi_tinh:
            xung_ho = "B√†"
        
        # Thay th·∫ø c√°c placeholder
        replacements = {
            '[Nguoi_LD]': ho_ten,
            '[Ngay_sinh]': ngay_sinh,
            '[Gioi_tinh]': gioi_tinh,
            '[Quoc_tich]': quoc_tich,
            '[So_CCCD]': so_cccd,
            '[Ngay_cap]': ngay_cap,
            '[Noi_cap]': noi_cap,
            '[Que_quan]': que_quan,
            '[DC_LH]': thuong_tru if thuong_tru else que_quan,
            '√îng/b√† :': f'{xung_ho}:',
            'H√¥m nay ng√†y ... th√°ng ... nƒÉm 2020': f'H√¥m nay ng√†y {current_day} th√°ng {current_month} nƒÉm {current_year}',
            '...': 'Tp. H·ªì Ch√≠ Minh',
        }
        
        for placeholder, value in replacements.items():
            contract = contract.replace(placeholder, value)
        
        return contract
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o h·ª£p ƒë·ªìng: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return None

def generate_pdf_contract(contract_text, output_file):
    """T·∫°o file PDF t·ª´ n·ªôi dung h·ª£p ƒë·ªìng v·ªõi h·ªó tr·ª£ ti·∫øng Vi·ªát"""
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import cm
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY
        import os
        
        # Th·ª≠ ƒëƒÉng k√Ω font ti·∫øng Vi·ªát
        font_name = 'Helvetica'  # Fallback
        try:
            # Th·ª≠ Times New Roman (h·ªó tr·ª£ t·ªët ti·∫øng Vi·ªát)
            font_paths = [
                "C:/Windows/Fonts/times.ttf",
                "C:/Windows/Fonts/timesbd.ttf",  # Bold
                "C:/Windows/Fonts/arial.ttf",
                "C:/Windows/Fonts/arialbd.ttf",  # Bold
            ]
            
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        font_base_name = os.path.splitext(os.path.basename(font_path))[0]
                        pdfmetrics.registerFont(TTFont(font_base_name, font_path))
                        if 'times' in font_base_name.lower():
                            font_name = font_base_name
                            break
                    except:
                        continue
        except:
            pass
        
        # T·∫°o document
        doc = SimpleDocTemplate(output_file, pagesize=A4,
                               rightMargin=2*cm, leftMargin=2*cm,
                               topMargin=2*cm, bottomMargin=2*cm)
        
        # T·∫°o style
        styles = getSampleStyleSheet()
        
        # Style cho ƒëo·∫°n vƒÉn th√¥ng th∆∞·ªùng
        normal_style = ParagraphStyle(
            'Normal_VN',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=11,
            leading=14,
            alignment=TA_LEFT,
            encoding='utf-8'
        )
        
        # Style cho ti√™u ƒë·ªÅ (cƒÉn gi·ªØa)
        title_style = ParagraphStyle(
            'Title_VN',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=14,
            leading=18,
            alignment=TA_CENTER,
            encoding='utf-8'
        )
        
        # T√°ch n·ªôi dung th√†nh c√°c d√≤ng v√† x·ª≠ l√Ω
        lines = contract_text.split('\n')
        story = []
        
        for line in lines:
            line = line.strip()
            if not line:
                story.append(Spacer(1, 0.2*cm))
                continue
            
            # Escape c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát cho HTML
            line_html = line.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            
            # Ki·ªÉm tra n·∫øu l√† ti√™u ƒë·ªÅ (ch·ªØ in hoa ho·∫∑c c√≥ ƒë·ªãnh d·∫°ng ƒë·∫∑c bi·ªát)
            if line.isupper() and len(line) < 100 and any(keyword in line for keyword in ['C·ªòNG H√íA', 'H·ª¢P ƒê·ªíNG', 'NG∆Ø·ªúI LAO ƒê·ªòNG', 'NG∆Ø·ªúI S·ª¨ D·ª§NG']):
                para = Paragraph(line_html, title_style)
            else:
                para = Paragraph(line_html, normal_style)
            
            story.append(para)
            story.append(Spacer(1, 0.2*cm))
        
        # Build PDF
        doc.build(story)
        return True
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o PDF: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return False

def save_to_excel(new_data):
    """Ghi d·ªØ li·ªáu m·ªõi v√†o file Excel v·ªõi ƒë·ªãnh d·∫°ng font ti·∫øng Vi·ªát v√† ƒë·ªô r·ªông c·ªôt"""
    try:
        from openpyxl.styles import Font, Alignment, PatternFill
        
        headers = ['S·ªë CCCD', 'H·ªç v√† t√™n', 'Ng√†y sinh', 'Gi·ªõi t√≠nh', 'Qu·ªëc t·ªãch', 
                  'Qu√™ qu√°n', 'N∆°i th∆∞·ªùng tr√∫', 'Ng√†y c·∫•p', 'N∆°i c·∫•p']
        
        try:
            wb = load_workbook(EXCEL_FILE)
            ws = wb.active
            
            # Ki·ªÉm tra xem ƒë√£ c√≥ header ch∆∞a
            if ws.max_row == 0 or ws.cell(1, 1).value is None:
                ws.append(headers)
        except FileNotFoundError:
            # T·∫°o file m·ªõi n·∫øu ch∆∞a t·ªìn t·∫°i
            wb = openpyxl.Workbook()
            ws = wb.active
            # Th√™m header
            ws.append(headers)
        
        # ƒê·ªãnh d·∫°ng header: font ti·∫øng Vi·ªát, ƒë·∫≠m, n·ªÅn xanh
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(name="Arial", size=11, bold=True, color="FFFFFF")
        
        for col_idx, header in enumerate(headers, start=1):
            cell = ws.cell(1, col_idx)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
        
        # Th√™m d·ªØ li·ªáu m·ªõi
        row_data = [
            new_data.get('S·ªë CCCD', ''),
            new_data.get('H·ªç v√† t√™n', ''),
            new_data.get('Ng√†y sinh', ''),
            new_data.get('Gi·ªõi t√≠nh', ''),
            new_data.get('Qu·ªëc t·ªãch', ''),
            new_data.get('Qu√™ qu√°n', ''),
            new_data.get('N∆°i th∆∞·ªùng tr√∫', ''),
            new_data.get('Ng√†y c·∫•p', ''),
            new_data.get('N∆°i c·∫•p', '')
        ]
        ws.append(row_data)
        
        # ƒê·ªãnh d·∫°ng d·ªØ li·ªáu: font ti·∫øng Vi·ªát, wrap text cho c√°c c·ªôt d√†i
        data_font = Font(name="Arial", size=10)
        column_widths = {
            'A': 18,  # S·ªë CCCD
            'B': 30,  # H·ªç v√† t√™n
            'C': 15,  # Ng√†y sinh
            'D': 12,  # Gi·ªõi t√≠nh
            'E': 15,  # Qu·ªëc t·ªãch
            'F': 50,  # Qu√™ qu√°n
            'G': 60,  # N∆°i th∆∞·ªùng tr√∫
            'H': 15,  # Ng√†y c·∫•p
            'I': 50   # N∆°i c·∫•p
        }
        
        # ƒêi·ªÅu ch·ªânh ƒë·ªô r·ªông c·ªôt
        for col_letter, width in column_widths.items():
            ws.column_dimensions[col_letter].width = width
        
        # ƒê·ªãnh d·∫°ng d·ªØ li·ªáu cho h√†ng m·ªõi
        new_row = ws.max_row
        for col_idx in range(1, len(headers) + 1):
            cell = ws.cell(new_row, col_idx)
            cell.font = data_font
            # Wrap text cho c√°c c·ªôt ƒë·ªãa ch·ªâ d√†i
            if col_idx in [6, 7, 9]:  # Qu√™ qu√°n, N∆°i th∆∞·ªùng tr√∫, N∆°i c·∫•p
                cell.alignment = Alignment(horizontal="left", vertical="top", wrap_text=True)
            else:
                cell.alignment = Alignment(horizontal="left", vertical="center")
        
        wb.save(EXCEL_FILE)
        return True
    except Exception as e:
        st.error(f"L·ªói khi ghi file Excel: {str(e)}")
        import traceback
        st.error(f"Chi ti·∫øt l·ªói: {traceback.format_exc()}")
        return False

# UI ch√≠nh
tab1, tab2 = st.tabs(["üì§ Nh·∫≠p CCCD m·ªõi", "üìã Danh s√°ch ƒë√£ l∆∞u"])

with tab1:
    st.header("Upload ·∫£nh CCCD m·∫∑t tr∆∞·ªõc v√† m·∫∑t sau")
    
    # C·∫•u h√¨nh OpenAI (n·∫øu c√≥)
    with st.expander("üîß C·∫•u h√¨nh n√¢ng cao (OpenAI API)", expanded=False):
        use_openai = st.checkbox("S·ª≠ d·ª•ng OpenAI API ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin ch√≠nh x√°c h∆°n", value=True)
        if use_openai:
            if not OPENAI_AVAILABLE:
                st.error("‚ö†Ô∏è Th∆∞ vi·ªán OpenAI ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Vui l√≤ng ch·∫°y: pip install openai")
                api_key = None
            else:
                api_key = st.text_input(
                    "OpenAI API Key",
                    type="password",
                    help="Nh·∫≠p API key c·ªßa b·∫°n t·ª´ https://platform.openai.com/api-keys",
                    value=st.session_state.get('openai_api_key', DEFAULT_API_KEY or '')
                )
                if api_key:
                    st.session_state['openai_api_key'] = api_key
                    st.success("‚úÖ API Key ƒë√£ ƒë∆∞·ª£c l∆∞u")
        else:
            api_key = None
            use_openai = False
    
    # Kh·ªüi t·∫°o bi·∫øn n·∫øu ch∆∞a c√≥
    if 'use_openai' not in locals():
        use_openai = True if DEFAULT_API_KEY else False
    if 'api_key' not in locals():
        api_key = st.session_state.get('openai_api_key', DEFAULT_API_KEY)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("M·∫∑t tr∆∞·ªõc")
        image_front_file = st.file_uploader(
            "Ch·ªçn ·∫£nh m·∫∑t tr∆∞·ªõc",
            type=['png', 'jpg', 'jpeg'],
            key="front"
        )
        if image_front_file:
            image_front = Image.open(image_front_file)
            st.image(image_front, caption="M·∫∑t tr∆∞·ªõc CCCD", use_container_width=True)
    
    with col2:
        st.subheader("M·∫∑t sau")
        image_back_file = st.file_uploader(
            "Ch·ªçn ·∫£nh m·∫∑t sau",
            type=['png', 'jpg', 'jpeg'],
            key="back"
        )
        if image_back_file:
            image_back = Image.open(image_back_file)
            st.image(image_back, caption="M·∫∑t sau CCCD", use_container_width=True)
    
    if image_front_file and image_back_file:
        if st.button("üîç Tr√≠ch xu·∫•t th√¥ng tin", type="primary"):
            cccd_info, full_text = process_cccd_extraction(image_front, image_back, use_openai, api_key)
            
            # ƒê·ªçc ri√™ng OCR text t·ª´ng m·∫∑t ƒë·ªÉ hi·ªÉn th·ªã debug
            text_front_debug = extract_text_with_ocr(image_front)
            text_back_debug = extract_text_with_ocr(image_back)
            
            # L∆∞u v√†o session_state ƒë·ªÉ gi·ªØ l·∫°i d·ªØ li·ªáu
            if cccd_info:
                st.session_state['cccd_info'] = cccd_info
                st.session_state['cccd_full_text'] = full_text
                st.session_state['text_front_debug'] = text_front_debug
                st.session_state['text_back_debug'] = text_back_debug
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            st.success("‚úÖ ƒê√£ tr√≠ch xu·∫•t th√¥ng tin!")
            
        # Hi·ªÉn th·ªã form ch·ªânh s·ª≠a th√¥ng tin (lu√¥n hi·ªÉn th·ªã n·∫øu c√≥ d·ªØ li·ªáu trong session_state)
        if 'cccd_info' in st.session_state and st.session_state['cccd_info']:
            cccd_info = st.session_state['cccd_info']
            
            # Hi·ªÉn th·ªã text OCR chi ti·∫øt (ƒë·ªÉ debug) n·∫øu c√≥
            if 'text_front_debug' in st.session_state:
                with st.expander("üêõ DEBUG: Text OCR ƒë√£ ƒë·ªçc (ƒê·ªÉ ki·ªÉm tra)", expanded=False):
                    st.write("**M·∫∂T TR∆Ø·ªöC (OCR Text):**")
                    st.text_area("", st.session_state['text_front_debug'], height=150, disabled=True, key="ocr_front_debug")
                    st.write("**M·∫∂T SAU (OCR Text):**")
                    st.text_area("", st.session_state.get('text_back_debug', ''), height=150, disabled=True, key="ocr_back_debug")
                    st.write("**Full Text (Combined):**")
                    st.text_area("", st.session_state.get('cccd_full_text', ''), height=100, disabled=True, key="ocr_full_debug")
                    
                    # Ki·ªÉm tra xem c√≥ t√¨m th·∫•y t·ª´ kh√≥a kh√¥ng
                    st.write("**üîç Ki·ªÉm tra t·ª´ kh√≥a:**")
                    text_front = st.session_state.get('text_front_debug', '')
                    text_back = st.session_state.get('text_back_debug', '')
                    keywords_check = {
                        "Qu√™ qu√°n": bool(re.search(r'Qu√™ qu√°n|Place of origin', text_front, re.IGNORECASE)),
                        "N∆°i th∆∞·ªùng tr√∫": bool(re.search(r'N∆°i th∆∞·ªùng tr√∫|Permanent address|Place of residence', text_back or text_front, re.IGNORECASE)),
                        "Ng√†y c·∫•p": bool(re.search(r'Ng√†y c·∫•p|Date of issue', text_back or text_front, re.IGNORECASE)),
                    }
                    for key, found in keywords_check.items():
                        status = "‚úÖ T√¨m th·∫•y" if found else "‚ùå KH√îNG t√¨m th·∫•y"
                        st.write(f"- {key}: {status}")
            
            # Form ch·ªânh s·ª≠a th√¥ng tin
            st.markdown("### **Vui l√≤ng ki·ªÉm tra v√† ch·ªânh s·ª≠a th√¥ng tin:**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                so_cccd = st.text_input("S·ªë CCCD", value=cccd_info.get('S·ªë CCCD', ''))
                ho_ten = st.text_input("H·ªç v√† t√™n", value=cccd_info.get('H·ªç v√† t√™n', ''))
                ngay_sinh = st.text_input("Ng√†y sinh", value=cccd_info.get('Ng√†y sinh', ''))
                gioi_tinh = st.text_input("Gi·ªõi t√≠nh", value=cccd_info.get('Gi·ªõi t√≠nh', ''))
                quoc_tich = st.text_input("Qu·ªëc t·ªãch", value=cccd_info.get('Qu·ªëc t·ªãch', ''))
            
            with col2:
                que_quan = st.text_area("Qu√™ qu√°n", value=cccd_info.get('Qu√™ qu√°n', ''))
                thuong_tru = st.text_area("N∆°i th∆∞·ªùng tr√∫", value=cccd_info.get('N∆°i th∆∞·ªùng tr√∫', ''))
                ngay_cap = st.text_input("Ng√†y c·∫•p", value=cccd_info.get('Ng√†y c·∫•p', ''))
                noi_cap = st.text_input("N∆°i c·∫•p", value=cccd_info.get('N∆°i c·∫•p', ''))
            
            col_btn1, col_btn2 = st.columns(2)
            
            with col_btn1:
                if st.button("üíæ L∆∞u v√†o Excel", type="primary", use_container_width=True):
                    final_data = {
                        'S·ªë CCCD': so_cccd,
                        'H·ªç v√† t√™n': ho_ten,
                        'Ng√†y sinh': ngay_sinh,
                        'Gi·ªõi t√≠nh': gioi_tinh,
                        'Qu·ªëc t·ªãch': quoc_tich,
                        'Qu√™ qu√°n': que_quan,
                        'N∆°i th∆∞·ªùng tr√∫': thuong_tru,
                        'Ng√†y c·∫•p': ngay_cap,
                        'N∆°i c·∫•p': noi_cap
                    }
                    
                    if save_to_excel(final_data):
                        st.success("‚úÖ ƒê√£ l∆∞u th√¥ng tin th√†nh c√¥ng v√†o file Excel!")
                        st.balloons()
                        # X√≥a d·ªØ li·ªáu trong session_state sau khi l∆∞u th√†nh c√¥ng
                        if 'cccd_info' in st.session_state:
                            del st.session_state['cccd_info']
                        if 'cccd_full_text' in st.session_state:
                            del st.session_state['cccd_full_text']
                        st.rerun()
                    else:
                        st.error("‚ùå L·ªói khi l∆∞u th√¥ng tin")
            
            with col_btn2:
                if st.button("üìÑ T·∫°o h·ª£p ƒë·ªìng lao ƒë·ªông (PDF)", type="secondary", use_container_width=True):
                    final_data = {
                        'S·ªë CCCD': so_cccd,
                        'H·ªç v√† t√™n': ho_ten,
                        'Ng√†y sinh': ngay_sinh,
                        'Gi·ªõi t√≠nh': gioi_tinh,
                        'Qu·ªëc t·ªãch': quoc_tich,
                        'Qu√™ qu√°n': que_quan,
                        'N∆°i th∆∞·ªùng tr√∫': thuong_tru,
                        'Ng√†y c·∫•p': ngay_cap,
                        'N∆°i c·∫•p': noi_cap
                    }
                    
                    # Ki·ªÉm tra xem c√≥ ƒë·ªß th√¥ng tin kh√¥ng
                    if not ho_ten or not so_cccd:
                        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin (H·ªç v√† t√™n, S·ªë CCCD) ƒë·ªÉ t·∫°o h·ª£p ƒë·ªìng")
                    else:
                        with st.spinner("ƒêang t·∫°o h·ª£p ƒë·ªìng lao ƒë·ªông..."):
                            # T·∫°o n·ªôi dung h·ª£p ƒë·ªìng
                            contract_text = create_labor_contract(final_data)
                            
                            if contract_text:
                                # T·∫°o t√™n file PDF
                                safe_name = "".join(c for c in ho_ten if c.isalnum() or c in (' ', '-', '_')).strip()
                                pdf_filename = f"HDLD_{safe_name}_{so_cccd}.pdf"
                                
                                # T·∫°o file PDF
                                if generate_pdf_contract(contract_text, pdf_filename):
                                    st.success(f"‚úÖ ƒê√£ t·∫°o h·ª£p ƒë·ªìng lao ƒë·ªông: {pdf_filename}")
                                    
                                    # ƒê·ªçc file PDF v√† cung c·∫•p download
                                    with open(pdf_filename, "rb") as pdf_file:
                                        st.download_button(
                                            label="üì• T·∫£i xu·ªëng h·ª£p ƒë·ªìng (PDF)",
                                            data=pdf_file,
                                            file_name=pdf_filename,
                                            mime="application/pdf",
                                            type="primary"
                                        )
    
    elif image_front_file or image_back_file:
        st.warning("‚ö†Ô∏è Vui l√≤ng upload c·∫£ 2 ·∫£nh (m·∫∑t tr∆∞·ªõc v√† m·∫∑t sau)")

with tab2:
    st.header("Danh s√°ch th√¥ng tin ƒë√£ l∆∞u")
    
    df = load_excel_data()
    
    if not df.empty:
        st.dataframe(df, use_container_width=True)
        
        # Th·ªëng k√™
        col1, col2 = st.columns(2)
        with col1:
            st.metric("T·ªïng s·ªë b·∫£n ghi", len(df))
        with col2:
            if st.button("üîÑ L√†m m·ªõi d·ªØ li·ªáu"):
                st.rerun()
    else:
        st.info("Ch∆∞a c√≥ th√¥ng tin n√†o ƒë∆∞·ª£c l∆∞u. Vui l√≤ng nh·∫≠p CCCD m·ªõi ·ªü tab 'Nh·∫≠p CCCD m·ªõi'")

st.markdown("---")
st.markdown(f"**File Excel:** `{EXCEL_FILE}`")
